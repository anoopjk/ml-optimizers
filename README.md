# ml-optimizers
Different type optimizers such as SGD, Momentum, RMSprop, Adam tested on MNIST dataset

## Usage

1. Download mnist data from https://github.com/golbin/TensorFlow-MNIST/tree/master/mnist/data
2. place the 4 files inside "mnist" folder
3. (Optional but recommended) create  conda environment and install the dependencies
```commandline
$ pip3 install -r requirements.txt
$ python3 adam.py
```

## Note
1. The mnist.py file is modified from the one in this repo https://github.com/hsjeong5/MNIST-for-Numpy
2. The optimizer file structure is inspired by this repo https://github.com/MaximeVandegar/Papers-in-100-Lines-of-Code
